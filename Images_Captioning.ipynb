{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyM/BRyE2fhN6GDvi4HZSbuR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itsmahadi007/AI/blob/master/Images_Captioning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You need additional files to run the code in this notebook. If you are on CoLab use these commands to install. (Check if the files are installed in the right directory (’A3DS’) after unzipping)."
      ],
      "metadata": {
        "id": "Zk_PlP2U5WuX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCZHnXIg5AOE"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/michael-franke/npNLG/raw/main/neural_pragmatic_nlg/data/A3DS/A3DS.zip\n",
        "!unzip A3DS.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "P4u5UxNh568q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##################################################\n",
        "## import packages\n",
        "##################################################\n",
        "\n",
        "from transformers import GPT2TokenizerFast, ViTImageProcessor, VisionEncoderDecoderModel\n",
        "from torch.utils.data import Dataset\n",
        "from torchtext.data import get_tokenizer\n",
        "import requests\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import pickle\n",
        "# from torchvision import transforms\n",
        "# from datasets import load_dataset\n",
        "# import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "yjr4iFD05eq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the pretrained model and its helper components\n",
        "\n",
        "We load the pre-trained neural image captioner like so:\n"
      ],
      "metadata": {
        "id": "lYt4nt1p6MKL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_raw = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")"
      ],
      "metadata": {
        "id": "UqRATgQw6XFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to be able to feed this image+language model with images and language, we need an image processor and a tokenizer that fits the model components used for encoding and decoding."
      ],
      "metadata": {
        "id": "4wZkT7_R6qm6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_processor = ViTImageProcessor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
        "tokenizer       = GPT2TokenizerFast.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")"
      ],
      "metadata": {
        "id": "-zje8FKi6rXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating captions\n",
        "You can insert URLs for pictures of your liking in this code to generate captions:"
      ],
      "metadata": {
        "id": "9FOfMmga6yLj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_n_generate(url, greedy = True, model = model_raw):\n",
        "    image = Image.open(requests.get(url, stream =True).raw)\n",
        "    pixel_values   = image_processor(image, return_tensors =\"pt\").pixel_values\n",
        "    plt.imshow(np.asarray(image))\n",
        "    plt.show()\n",
        "\n",
        "    if greedy:\n",
        "        generated_ids  = model.generate(pixel_values, max_new_tokens = 30)\n",
        "    else:\n",
        "        generated_ids  = model.generate(\n",
        "            pixel_values,\n",
        "            do_sample=True,\n",
        "            max_new_tokens = 30,\n",
        "            top_k=5)\n",
        "    generated_text = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "    print(generated_text)\n",
        "\n",
        "# url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
        "# url = \"https://raw.githubusercontent.com/michael-franke/npNLG/main/neural_pragmatic_nlg/pics/06-3DS-example.jpg\"\n",
        "# url = \"https://img.welt.de/img/sport/mobile102025155/9292509877-ci102l-w1024/hrubesch-rummenigge-BM-Berlin-Gijon-jpg.jpg\"\n",
        "url = \"https://faroutmagazine.co.uk/static/uploads/2021/09/The-Cover-Uncovered-The-severity-of-Rage-Against-the-Machines-political-message.jpg\"\n",
        "# url = \"https://media.npr.org/assets/img/2022/03/13/2ukraine-stamp_custom-30c6e3889c98487086d76869f8ba6a8bfd2fd5a1.jpg\"\n",
        "\n",
        "show_n_generate(url, greedy = False)"
      ],
      "metadata": {
        "id": "iJMMFCom62nZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}